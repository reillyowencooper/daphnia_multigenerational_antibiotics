---
title: "Statistical analysis"
author: "David Nguyen"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(multcomp) # for glht
library(broom)
library(cowplot)
library(here)
library(pscl) # for hurdle models
theme_set(theme_cowplot())
```


```{r message = FALSE}
life_history_loc <- here("data", "life_history.csv")
life_history <- read_csv(life_history_loc)

lh_df <-
  life_history %>%
  rowwise() %>%
  mutate(total_offspring = sum(brood_one_numoffspring, brood_two_numoffspring, brood_three_numoffspring, na.rm = TRUE)) %>%
  mutate(genf = factor(gen),
         treatment = ifelse(treatment == "recovery", "control", treatment)) %>%
  mutate(sequence = substr(figure_labels, 1,2),
         sequence = ifelse(str_detect(sequence, "C"), "C", sequence),
         sequence = ifelse(str_detect(sequence, "A"), "A", sequence),
         sequence = factor(sequence)
         )
```


# Cell means model for Final Size

This model has a parameter for every single cell mean. That is, every sequence x generation combination for $i = 1,2,3, \ldots, 6$ sequences and $j = 0, 1, \ldots, 4$ generations. There are 20 combindations total (some combinations were not included in experimental design).

$$y_{ijk} = \tau_{ij} + \epsilon_{ijk}$$

* $y_{ijk}$ the final size of the $k^{th}$ daphnia in the $i^{th}$ sequence and $j^{th}$ generation
* $\tau_{ij}$ is the mean final size of daphnia in the $i^{th}$ sequence and $j^{th}$ generation
* $\epsilon_{ijk} \sim N(0,\sigma^2)$ is random error

```{r}
# create a col with cominations of sequence and generation
seq_gen_levels <- c(paste("C", ":", 0:4, sep = ""), 
                    paste("R1", ":", 1:4, sep = ""),
                    paste("R2", ":", 2:4, sep = ""),
                    paste("R3", ":", 3:4, sep = ""),
                    paste("R4", ":", 4, sep = ""),
                    paste("A", ":", 0:4, sep = ""))
# bod <- bod %>% mutate(seq_gen = paste(fsequence, ":", fgen, sep = ""),
#                       seq_gen = factor(seq_gen,
#                                        levels = seq_gen_levels))
lh_df <- lh_df %>% mutate(seq_gen = paste(sequence, ":", gen, sep = ""),
                      seq_gen = factor(seq_gen,
                                       levels = seq_gen_levels))


# fit model
# mod.size <- lm(final_size ~ seq_gen - 1, data = bod)
mod.size <- lm(final_size ~ seq_gen - 1, data = lh_df)
summary(mod.size)
```

# Model fit

```{r}
aug.size <-
  augment(mod.size, se_fit = TRUE) %>%
  mutate(width = qnorm(0.975)*sqrt(.se.fit),
         lwr = .fitted - width,
         upr = .fitted + width)
aug.size <- aug.size %>% inner_join(lh_df)

aug.size %>%
  ggplot() +
  geom_jitter(aes(x = gen, y = final_size), alpha = 0.3) +
  geom_point(aes(x = gen, y = .fitted), size = 2) +
  geom_errorbar(aes(x = gen, ymin = lwr, ymax = upr), width = 0) +
  facet_wrap(~sequence) +
  labs(y = "Final size in mm (95% CI)",
       x = "Generation")
```

Estimated cell means and 95% Wald confidence intervals unadjusted for family-wise error.

# Contrasts for body size analysis

```{r}
# get unique rows of model matrix
cells <- model.matrix(mod.size) %>% unique()
colnames(cells) <- colnames(cells) %>% str_remove(pattern = "seq_gen")

# name each row so we can reference it according to seq X gen combinations
# rownames(cells) <- names(actual_combos)

cell_rownames <- vector("character", length = nrow(cells))
for ( i in seq_along(cell_rownames)) {
  cell_rownames[i] <- colnames(cells)[cells[i,] == 1]
}

# clean up names
# colnames(cells) <- colnames(cells) %>% str_remove(pattern = "seq_gen")
rownames(cells) <- cell_rownames # colnames(cells)

# check that indexing is consistent with model coef order
# ((names(coef(mod.size)) %>% str_remove(pattern = "seq_gen")) == colnames(cells)) %>% sum() == length(coef(mod.size))
```

```{r}
# try using emmeans package
library(emmeans)
em.size <- emmeans(mod.size, "seq_gen")
em.sizedf <- data.frame(em.size)
```

```{r}
plot_size <-
  em.sizedf %>% 
  separate(col = seq_gen, into = c("sequence", "gen"), sep = ":", remove = FALSE) %>%
  mutate(sequence = factor(sequence, levels = levels(lh_df$sequence)),
         gen = factor(gen))

ggplot() +
  geom_jitter(data = lh_df, mapping = aes(x = gen, y = final_size, col = factor(gen)), alpha = 0.5) +
  geom_point(data = plot_size, mapping = aes(x = as.integer(gen) - 1, y = emmean), size = 2) +
  geom_errorbar(data = plot_size, mapping = aes(x = as.integer(gen) - 1, ymin = lower.CL, ymax = upper.CL)) +
  facet_wrap(~sequence) +
  labs(x = "generation", y = "final size in mm (95% CI)",
       col = "generation")
```

Estimated cell means and 95% Wald confidence intervals adjusted for family-wise error.

```{r eval = FALSE}
# compare emmeans to observed cell means
# they are equal
obs_mean <- bod %>% group_by(seq_gen) %>% summarise(cell_mean = mean(final_size, na.rm = TRUE)) 
inner_join(em.sizedf, obs_mean) %>% transmute(diff = near(emmean, cell_mean))
```

### Compare mean body size among sequences to control within each generation

```{r cache=TRUE}
# put K into a list since ethat is what emmeans::contrast needs to specify linear hypothesis
contrast_list_in_gen <- list(cells["C:0",] - cells["A:0",],
           cells["C:1",] - cells["R1:1",],
           cells["C:1",] - cells["A:1",],
           cells["C:2",] - cells["R1:2",],
           cells["C:2",] - cells["R2:2",],
           cells["C:2",] - cells["A:2",],
           cells["C:3",] - cells["R1:3",],
           cells["C:3",] - cells["R2:3",],
           cells["C:3",] - cells["R3:3",],
           cells["C:3",] - cells["A:3",],
           cells["C:4",] - cells["R1:4",],
           cells["C:4",] - cells["R2:4",],
           cells["C:4",] - cells["R3:4",],
           cells["C:4",] - cells["R4:4",],
           cells["C:4",] - cells["A:4",])
hypothesis_names <- c("Generation 0: C - A",
                      "Generation 1: C - R1", "Generation 1: C - A",
                      "Generation 2: C - R1", "Generation 2: C - R2", "Generation 2: C - A",
                      "Generation 3: C - R1", "Generation 3: C - R2", "Generation 3: C - R3", "Generation 3: C - A",
                      "Generation 4: C - R1", "Generation 4: C - R2", "Generation 4: C - R3", "Generation 4: C - R4", 
                      "Generation 4: C - A")
names(contrast_list_in_gen) <- hypothesis_names

# get contrasts using mvt adjustment
LF_in_gen <- contrast(em.size, 
               contrast_list_in_gen,
               adjust = "mvt")
# save estimate, CI, and p.value
sum_in_gen <- summary(LF_in_gen) %>% data.frame()
contr_in_gen <- confint(LF_in_gen) %>% data.frame()
contr_in_gen <- contr_in_gen %>% add_column(p.value = sum_in_gen$p.value)

# shorten contrast name, make a col for generation
contr_in_gen <-
  contr_in_gen %>% 
  separate(contrast, into = c("generation", "contrast_name"), sep = ":", remove = FALSE) %>% 
  mutate(generation = str_remove(generation, "Generation "),
         generation = factor(generation))

contr_in_gen %>% knitr::kable()
```

```{r}
contr_in_gen_path <- paste(here("statistics"), "/growth_constrast_in_gen.csv", sep = "")
write_csv(contr_in_gen, path = contr_in_gen_path)
```


```{r}
contr_in_gen %>%
  ggplot() +
  geom_hline(yintercept = 0, col = "red", linetype = "dashed") +
  geom_point(aes(x = contrast, y = estimate, col = generation), size = 2) +
  geom_errorbar(aes(x = contrast, ymin = lower.CL, ymax = upper.CL, col = generation)) +
  scale_x_discrete(labels=contr_in_gen$contrast_name) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(x = "Comparison",
       y = "Difference in body size (mm)")
```

### Compare difference in body size over the course of the experiment

```{r cache=TRUE}
# put K into a list since ethat is what emmeans::contrast needs to specify linear hypothesis
contrast_list_time <- list("C: gen 0 - gen 4" = cells["C:0",] - cells["C:4",],
                      "A: gen 0 - gen 4" = cells["A:0",] - cells["A:4",],
                      "gen 0 - gen 4: C - A" = (cells["C:0",] - cells["C:4",]) - (cells["A:0",] - cells["A:4",]))

LF_time <- contrast(em.size, 
               contrast_list_time,
               adjust = "mvt")
sum_time <- summary(LF_time) %>% data.frame()
contr_time <- confint(LF_time) %>% data.frame()
contr_time <- contr_time %>% add_column(p.value = sum_time$p.value)
contr_time %>% knitr::kable()

# save contrasts
contr_time_path <- paste(here("statistics"), "/growth_constrast_time.csv", sep = "")
write_csv(contr_time, path = contr_time_path)
```

```{r}
contr_time %>%
  ggplot() +
   geom_hline(yintercept = 0, col = "red", linetype = "dashed") +
  geom_point(aes(x = contrast, y = estimate), size = 2) + 
  geom_errorbar(aes(x = contrast, ymin = lower.CL, ymax = upper.CL), width = 0) +
  labs(y = "difference in body size (mm)")
```
### Compare the mean body size at first recovery time by number of generations exposed to antibiotics

```{r cache=TRUE}
contrast_list_first_recovery <- 
  list("R1 - R2" = cells["R1:1",] - cells["R2:2",],
       "R1 - R3" = cells["R1:1",] - cells["R3:3",],
       "R1 - R4" = cells["R1:1",] - cells["R4:4",],
       "R2 - R3" = cells["R2:2",] - cells["R3:3",],
       "R2 - R4" = cells["R2:2",] - cells["R4:4",],
       "R3 - R4" = cells["R3:3",] - cells["R4:4",])

LF_first_recovery <- contrast(em.size,
                              contrast_list_first_recovery,
                              adjust = "mvt")
sum_first_recovery <- summary(LF_first_recovery) %>% data.frame()
first_recovery <- confint(LF_first_recovery) %>% data.frame()

first_recovery <- first_recovery %>% add_column(p.value = sum_first_recovery$p.value)

first_recovery %>% knitr::kable()

# save contrasts
contr_recovery_path <- paste(here("statistics"), "/growth_constrast_recovery.csv", sep = "")
write_csv(first_recovery, path = contr_recovery_path)

first_recovery %>%
  ggplot() +
   geom_hline(yintercept = 0, col = "red", linetype = "dashed") +
  geom_point(aes(x = contrast, y = estimate), size = 2) + 
  geom_errorbar(aes(x = contrast, ymin = lower.CL, ymax = upper.CL), width = 0) +
  labs(y = "difference in body size (mm)")
```


### Model Checking

```{r}
# model checking
plot(mod.size)
```

Everything looks good.

# Cumulative reproduction analysis

### Exploratory data viz

```{r}
zeros_df <-
  lh_df %>% 
  rowwise() %>%
  mutate(no_offspring = (total_offspring == 0)) %>%
  group_by(sequence, gen) %>%
  summarise(zeros = sum(no_offspring))
  # filter(total_offspring == 0) %>%
zeros_table <- 
  zeros_df %>%
  pivot_wider(names_from = "gen", values_from = "zeros")

c.total <- data.frame(sequence = "total",
           t(apply(zeros_table[,-1], 2, sum, na.rm = TRUE))) # gen totals
names(c.total) <- c("sequence",0:4)
total_zeros <- sum(c.total[-1])

r.total <- data.frame(total = c(apply(zeros_table[,-1], 1, sum, na.rm = TRUE), # sequence totals
                                total_zeros)) # total zeros over gen and sequence
# check total zeros
sum(r.total[-nrow(r.total),]) == total_zeros # they are the same

zeros_table <- zeros_table %>% ungroup() %>% add_row(c.total) %>% add_column(r.total)

options(knitr.kable.NA = '*')
zeros_table %>% knitr::kable()
```

There are some instances where there were no zeros in a sequence x generation group. This means I can't fit a satruated logistic model for the zeros.

```{r}
lh_df %>%
  ggplot() +
  geom_jitter(aes(x = final_survival_day, y =total_offspring), alpha = 0.5) +
  geom_hline(yintercept = 0, col = "red") +
  facet_grid(sequence~gen) + labs(title = "Total offspring by final survival day")
```

we can see that there are two kinds "paths" that can result in zero offspring:

* Biological sterility: these are the individuals (4 in this dataset) that reached the 21 day survival endpoint but never had offspring. About 1/100 daphnia are like this.
* Failure to survive reproductive maturation: between about 5 - 10 days of age, daphnia undergo a stressful shift in resource allocation towards reproduction. Not all daphnia survive this.

If excess zeros need to be modeled, I think that a "hurdle" model is most appropriate. The hurdle would be getting passed reproductive maturation and not being sterile.

Whats up with the A:4 individual that had 20 babies and died at 1 day old?

```{r}
lh_df %>% filter(sequence == "A", total_offspring > 10, final_survival_day < 10) %>%
    dplyr::select(gen, treatment, final_survival_day, final_size,
                brood_one_numoffspring, brood_two_numoffspring, brood_three_numoffspring, total_offspring) %>%
  knitr::kable()
```

Yeah, there is definitily a data entry error here. It looks like there are two records where the day of first brood is greater than the final survival day. They were probably swapped on accident.

```{r}
lh_df %>% filter(brood_one_day > final_survival_day) %>% 
  dplyr::select(gen, treatment, individual, final_survival_day, brood_one_day) %>% 
  knitr::kable()
```

### Approach

* Fit non zero-inflated models
* Fit zero-inflated models
* compare number of zeros predicted by each to see which is better

```{r}
glm_pois <- glm(total_offspring ~ seq_gen, family = poisson(link = "log"), data = lh_df)
glm_negbin <- glm.nb(total_offspring ~ seq_gen, link = "log", data = lh_df)

summary(glm_pois)
summary(glm_negbin)
```

```{r}
AIC(glm_pois, glm_negbin)
```

Saturated negative binomial is better than saturated poisson model.

```{r}
par(mfrow = c(2,1))
plot(glm_pois, which = 1)
plot(glm_negbin, which = 1)
```

```{r}
par(mfrow = c(2,1))
plot(glm_pois, which = 2)
plot(glm_negbin, which = 2)
```


```{r}
plot(glm_pois, which = 3)
plot(glm_negbin, which = 3)
```

```{r}
par(mfrow = c(2,1))
plot(glm_pois, which = 4)
plot(glm_negbin, which = 4)
```

Don't know how to interpret this.

### Compare predicted zeros to observed zeros

```{r}
pred_df <- data.frame(seq_gen = seq_gen_levels) %>%
  separate(col = seq_gen, into = c("sequence", "gen"), sep = ":", remove = FALSE) %>%
  mutate(sequence = factor(sequence, levels = levels(lh_df$sequence)),
         gen = factor(gen))
obs_zeros_df <- 
  zeros_df %>% mutate(seq_gen = paste(sequence, ":", gen, sep = ""),
                      seq_gen = factor(seq_gen,
                                       levels = seq_gen_levels)) %>% 
             ungroup() %>%
             dplyr::select(seq_gen, obs_zeros = zeros) 
cell_count_df <- lh_df %>% group_by(seq_gen) %>% summarise(cell_count = n())
pred_df <- inner_join(pred_df, cell_count_df, by = "seq_gen")
pred_df <- inner_join(pred_df, obs_zeros_df, by = "seq_gen")

pred_df$pois_mean <- predict(glm_pois, newdata = pred_df, type = "response")
pred_df$nb_mean <- predict(glm_negbin, newdata = pred_df, type = "response")

pred_df <- pred_df %>% 
  mutate(pzero_pois = ppois(0, lambda = pois_mean),
         pzero_nb = pnbinom(0, size = glm_negbin$theta, mu = nb_mean),
         pred_zero_pois = cell_count*pzero_pois,
         pred_zero_nb = cell_count*pzero_nb)
```

```{r fig.show="hold", out.width="50%"}
#  poisson
pred_df %>%
  ggplot(aes(x = seq_gen)) +
  geom_point(aes(y = obs_zeros), col = "red", size = 2, alpha = 0.5) +
  geom_point(aes(y = pred_zero_pois), col = "blue", size = 2, alpha = 0.5) +
  geom_segment(aes(x = seq_gen, xend = seq_gen, y = pred_zero_pois, yend = obs_zeros)) +
  coord_flip() +
  labs(title = "Comparing predicted and observed zeros: poisson",
       subtitle = "observed = red, predicted = blue",
       x = "number of daphnia with zero offspring",
       y = "group")
# nbinom
pred_df %>%
  ggplot(aes(x = seq_gen)) +
  geom_point(aes(y = obs_zeros), col = "red", size = 2, alpha = 0.5) +
  geom_point(aes(y = pred_zero_nb), col = "blue", size = 2, alpha = 0.5) +
  geom_segment(aes(x = seq_gen, xend = seq_gen, y = pred_zero_nb, yend = obs_zeros)) +
  coord_flip() +
  labs(title = "Comparing predicted and observed zeros: negative binomial",
       subtitle = "observed = red, predicted = blue",
       x = "number of daphnia with zero offspring",
       y = "group")
```

Obviously, the poisson model underestimates the number of zeros. Negative binomial does a little better but still mostly underpredicts the number of zeros.

### Hurdle models

```{r}
# determine model for whether Pr( offspring > 0 )
glm_bin <- glm(I(total_offspring > 0) ~ sequence * factor(gen), family = binomial, data = lh_df)
summary(glm_bin)
car::Anova(glm_bin)
```

Interaction isn't significant. But, there are tons of NA for parameter estimates due to missing combinations and over-parameterization. Ignoring this for now, I'll use the sequence and generation without interaction as covariates for the hurdle part of the model. EDIT: actually, I shouldn't even be considering this "saturated" model, because of complete seperation. See below.

```{r}
# check for convergence issues
glm_bin2 <- glm(I(total_offspring > 0) ~ sequence * factor(gen), family = binomial, data = lh_df,
                control = list(maxit = 50, epsilon = 1e-12))
cbind(coef(glm_bin), coef(glm_bin2))
```

There's clear evidence for complete seperation (which we already knew because some cells have zero instances of no offspring). But are there problems with the no interaction logistic regression?

```{r}
# check for convergence issues
glm_bin <- glm(I(total_offspring > 0) ~ sequence + factor(gen), family = binomial, data = lh_df)
glm_bin2 <- glm(I(total_offspring > 0) ~ sequence + factor(gen), family = binomial, data = lh_df,
                control = list(maxit = 50, epsilon = 1e-12))
cbind(coef(glm_bin), coef(glm_bin2))
```

No, there are not problems. So maybe a more important reason for using this linear predictor is that the model can actually converge.

```{r}
hurdle_pois <-
  hurdle(total_offspring ~ seq_gen -1 | sequence + factor(gen), 
       dist = "poisson", zero.dist = "binomial", data = lh_df)
hurdle_nb <-
  hurdle(total_offspring ~ seq_gen -1 | sequence + factor(gen), 
       dist = "negbin", zero.dist = "binomial", data = lh_df)

summary(hurdle_pois)
summary(hurdle_nb)
```

```{r}
AIC(hurdle_pois, hurdle_nb)
```

```{r}
pred_df$pzero_hurdle_pois <- 1 - predict(hurdle_pois, newdata = pred_df, type = "zero") # returns prob > 0?
pred_df$pzero_hurdle_nb <- 1 - predict(hurdle_nb, newdata = pred_df, type = "zero") # returns prob > 0?
pred_df <- pred_df %>% 
  mutate(pred_zero_hurdle_pois = pzero_hurdle_pois*cell_count,
         pred_zero_hurdle_nb = pzero_hurdle_nb*cell_count)
```

```{r}
pred_df %>% summarise(total_pois = sum(pred_zero_pois),
                      total_nb = sum(pred_zero_nb),
                      total_hurdle_pois = sum(pred_zero_hurdle_pois),
                      total_hurdle_nb = sum(pred_zero_hurdle_nb),
                      total_observed = sum(obs_zeros)) %>%
  knitr::kable()
```

The predicted number of daphnia with no offspring using hurdle models is clearly more consistent with the observed number of zeros. The non-hurdle models perform very poorly.

```{r fig.show = "hold", out.width = "50%"}
#  poisson
pred_df %>%
  ggplot(aes(x = seq_gen)) +
  geom_point(aes(y = obs_zeros), col = "red", size = 2, alpha = 0.5) +
  geom_point(aes(y = pred_zero_hurdle_pois), col = "blue", size = 2, alpha = 0.5) +
  geom_segment(aes(x = seq_gen, xend = seq_gen, y = pred_zero_hurdle_pois, yend = obs_zeros)) +
  coord_flip() +
  labs(title = "Comparing predicted and observed zeros: hurdle poisson",
       subtitle = "observed = red, predicted = blue",
       x = "number of daphnia with zero offspring",
       y = "group")
# nbinom
pred_df %>%
  ggplot(aes(x = seq_gen)) +
  geom_point(aes(y = obs_zeros), col = "red", size = 2, alpha = 0.5) +
  geom_point(aes(y = pred_zero_hurdle_nb), col = "blue", size = 2, alpha = 0.5) +
  geom_segment(aes(x = seq_gen, xend = seq_gen, y = pred_zero_hurdle_nb, yend = obs_zeros)) +
  coord_flip() +
  labs(title = "Comparing predicted and observed zeros: hurdle negative binomial",
       subtitle = "observed = red, predicted = blue",
       x = "number of daphnia with zero offspring",
       y = "group")

```

Visually, there do not appear to be clear differences between the prediction of zeros between the poisson and negative binomial models. In retrospect, this should be obvious, since both the logistic model parts of the hurdle models are using the exact same covariates and response data so they should give the same predicted numbers of zeros.

To really see why the AIC of the negative binomial model is smaller, we need to look at the predicted counts.

```{r}
pred_df$pred_response_hurdle_pois = predict(hurdle_pois, newdata = pred_df, type = "response") 
pred_df$pred_response_hurdle_nb = predict(hurdle_nb, newdata = pred_df, type = "response") 

# plots
ggplot() +
  geom_jitter(data = lh_df, mapping = aes(x = gen, y = total_offspring, col = factor(gen)), alpha = 0.5) +
  geom_point(data = pred_df, mapping = aes(x = as.integer(gen) -1.1, y = pred_response_hurdle_pois), 
             col = "red", size = 2) +
  geom_point(data = pred_df, mapping = aes(x = as.integer(gen) -0.9, y = pred_response_hurdle_nb), 
             col = "blue", size = 2) +
  facet_wrap(~sequence) +
  labs(title = "Comparison of predicted offspring to observed offspring",
       subtitle = "red = poisson, blue = negative binomial",
       x = "generation", y = "cumulative reproduction")
```

Ok, so the mean predicted number of offspring is the same for both models. The negative binomial model is probably more likely because it accomodates the overdispersion better than the poisson. 

# Contrasts for cumulative reproduction analysis

All of the following results use the hurdle model with the truncated negative binomial random component for cumulative reproduction. The probability of overcoming the hurdle is modeled using the additive effects of sequence and generation, since the interaction was not significant for the zero count model. (need to figure out notation for hurdle model)

All p-values and confidence intervals were adjusted for multiple comparisons using the multivariate t-distribution. Family-wise confidence level was set at 95% for each of the groups of comparisons, i.e., for each plot presented below.


```{r}
em.repro <- emmeans(hurdle_nb, "seq_gen", nesting = NULL, mode = "response")
em.reprodf <- data.frame(em.repro)
```

```{r}
plot_repro <-
  em.reprodf %>% 
  separate(col = seq_gen, into = c("sequence", "gen"), sep = ":", remove = FALSE) %>%
  mutate(sequence = factor(sequence, levels = levels(lh_df$sequence)),
         gen = factor(gen))

ggplot() +
  geom_jitter(data = lh_df, mapping = aes(x = gen, y = total_offspring, col = factor(gen)), alpha = 0.5) +
  geom_point(data = plot_repro, mapping = aes(x = as.integer(gen) - 1, y = emmean), size = 2) +
  geom_errorbar(data = plot_repro, mapping = aes(x = as.integer(gen) - 1, ymin = lower.CL, ymax = upper.CL)) +
  facet_wrap(~sequence) +
  labs(x = "generation", y = "cumulative reproduction",
       col = "generation")
```

Plot of expected cumulative reproduction from negative binomial hurdle model with 95% Wald CI adjusted for family-wise error.

### Compare mean cumulative reproduction among sequences to control within each generation

```{r }
# get contrasts using mvt adjustment
LF_in_gen <- contrast(em.repro, 
               contrast_list_in_gen,
               adjust = "mvt")
# save estimate, CI, and p.value
sum_in_gen <- summary(LF_in_gen) %>% data.frame()
contr_in_gen <- confint(LF_in_gen) %>% data.frame()
contr_in_gen <- contr_in_gen %>% add_column(p.value = sum_in_gen$p.value)

# shorten contrast name, make a col for generation
contr_in_gen <-
  contr_in_gen %>% 
  separate(contrast, into = c("generation", "contrast_name"), sep = ":", remove = FALSE) %>% 
  mutate(generation = str_remove(generation, "Generation "),
         generation = factor(generation))
```

```{r}
# save contrasts
contr_in_gen_path <- paste(here("statistics"), "/repro_constrast_in_gen.csv", sep = "")
write_csv(contr_in_gen, path = contr_in_gen_path)

```


```{r}
contr_in_gen %>% dplyr::select(-generation, contrast_name) %>% knitr::kable(digits = 3)
```



```{r}
contr_in_gen %>%
  ggplot() +
  geom_hline(yintercept = 0, col = "red", linetype = "dashed") +
  geom_point(aes(x = contrast, y = estimate, col = generation), size = 2) +
  geom_errorbar(aes(x = contrast, ymin = lower.CL, ymax = upper.CL, col = generation)) +
  scale_x_discrete(labels=contr_in_gen$contrast_name) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(x = "Comparison",
       y = "Difference in cumulative reproduction")
```

Similar to the body size results, the differences do not seem to follow any scientifically meaningful pattern.

### Compare difference in mean cumulative reproduction over the course of the experiment

```{r cache=TRUE}
# put K into a list since ethat is what emmeans::contrast needs to specify linear hypothesis
contrast_list_time <- list("C: gen 0 - gen 4" = cells["C:0",] - cells["C:4",],
                      "A: gen 0 - gen 4" = cells["A:0",] - cells["A:4",],
                      "gen 0 - gen 4: C - A" = (cells["C:0",] - cells["C:4",]) - (cells["A:0",] - cells["A:4",]))

LF_time <- contrast(em.repro, 
               contrast_list_time,
               adjust = "mvt")
sum_time <- summary(LF_time) %>% data.frame()
contr_time <- confint(LF_time) %>% data.frame()
contr_time <- contr_time %>% add_column(p.value = sum_time$p.value)
```

```{r}
contr_time %>% knitr::kable(digits = 3)
```

```{r}
# save contrasts
contr_time_path <- paste(here("statistics"), "/repro_constrast_time.csv", sep = "")
write_csv(contr_time, path = contr_time_path)
```


```{r}
contr_time %>%
  ggplot() +
   geom_hline(yintercept = 0, col = "red", linetype = "dashed") +
  geom_point(aes(x = contrast, y = estimate), size = 2) + 
  geom_errorbar(aes(x = contrast, ymin = lower.CL, ymax = upper.CL), width = 0) +
  labs(y = "difference in cumulative reproduction")
```

Cumulative reproduction decreased from generation 0 to generation 4 for both antibiotic and control sequences. The change in cumulative was 7.3 (SE = 1.64) offspring greater for daphnia in the antibiotic sequence compared to the control sequence.

### Compare the mean cummulative reproduction at first recovery time by number of generations exposed to antibiotics

```{r cache=TRUE}
contrast_list_first_recovery <- 
  list("R1 - R2" = cells["R1:1",] - cells["R2:2",],
       "R1 - R3" = cells["R1:1",] - cells["R3:3",],
       "R1 - R4" = cells["R1:1",] - cells["R4:4",],
       "R2 - R3" = cells["R2:2",] - cells["R3:3",],
       "R2 - R4" = cells["R2:2",] - cells["R4:4",],
       "R3 - R4" = cells["R3:3",] - cells["R4:4",])

LF_first_recovery <- contrast(em.repro,
                              contrast_list_first_recovery,
                              adjust = "mvt")
sum_first_recovery <- summary(LF_first_recovery) %>% data.frame()
first_recovery <- confint(LF_first_recovery) %>% data.frame()

first_recovery <- first_recovery %>% add_column(p.value = sum_first_recovery$p.value)
```

```{r}
first_recovery %>% knitr::kable()
```

```{r}
# save contrasts
contr_recovery_path <- paste(here("statistics"), "/repro_constrast_recovery.csv", sep = "")
write_csv(first_recovery, path = contr_recovery_path)
```


```{r}
first_recovery %>%
  ggplot() +
   geom_hline(yintercept = 0, col = "red", linetype = "dashed") +
  geom_point(aes(x = contrast, y = estimate), size = 2) + 
  geom_errorbar(aes(x = contrast, ymin = lower.CL, ymax = upper.CL), width = 0) +
  labs(y = "difference in cumulative reproduction")
```

It is challenging to interpret these results because they are confounded by the generation specific differences in reproduction.
